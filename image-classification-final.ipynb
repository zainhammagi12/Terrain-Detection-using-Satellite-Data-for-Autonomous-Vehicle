{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport os  # Library for operating system-related functions\nimport numpy as np  # Numerical computing library\nimport matplotlib.pyplot as plt  # Plotting library\nimport seaborn as sns  # Statistical data visualization library\nimport tensorflow as tf  # TensorFlow machine learning framework\nimport tensorflow_datasets as tfds  # TensorFlow Datasets library\nimport tensorflow_hub as hub  # TensorFlow Hub for pre-trained models\nimport tensorflow_addons as tfa  # TensorFlow Addons for additional functions\nfrom tensorflow.keras.layers import Dense, Dropout  # Layers for building neural networks\nfrom tensorflow.keras.callbacks import EarlyStopping  # Callback for early stopping during training","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Dataset from TensorFlow Datasets","metadata":{}},{"cell_type":"code","source":"# importing all the images from meta data\nall_data= tfds.load(\"eurosat\", with_info=True) \n\n#Dividing dataset into train, validation and test\ntrain_ds = tfds.load(\"eurosat\", split=\"train[:60%]\")\ntest_ds  = tfds.load(\"eurosat\", split=\"train[60%:80%]\")\nvalid_ds = tfds.load(\"eurosat\", split=\"train[80%:]\")\n\n#Storing Class names\nclass_names = all_data[1].features[\"label\"].names\nnum_classes = len(class_names)\nnum_examples = all_data[1].splits[\"train\"].num_examples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting a bar graph to visualize class distribution\nfig, ax = plt.subplots(1, 1, figsize=(10,5))\n\n# Counting the occurrences of each class label\nlabels, counts = np.unique(np.fromiter(all_data[0][\"train\"].map(lambda x: x[\"label\"]), np.int32), return_counts=True)\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=90)\n\n# Set y and x axis labels\nplt.ylabel('Count')\nplt.xlabel('Classes')\n\n# Create a bar plot using seaborn\nsns.barplot(x=[class_names[l] for l in labels], y=counts, ax=ax, color=None)\n\n# Add count annotations to the bars\nfor i, x in enumerate(labels):\n    ax.text(x - 0.2, counts[i] + 5, counts[i])\n\n# Set the title of the plot\nax.set_title(\"Number per class\")\n\n# Save the plot as an image\nplt.savefig('sample_plot.png')\n\n# Display the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Function to apply data augmentation to an image-label pair\ndef augment(image, label):\n    # Randomly flip the image horizontally\n    image = tf.image.random_flip_left_right(image)\n    \n    # Randomly adjust the brightness of the image\n    image = tf.image.random_brightness(image, max_delta=0.1)\n    \n    # Randomly adjust the contrast of the image\n    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n    \n    return image, label\n\n\n# Function to prepare a dataset for training\ndef prepare_for_training(dataset, cache=True, augment_data=True, batch_size=64, shuffle_buffer_size=1000):\n    # Cache the dataset if specified\n    if cache:\n        if isinstance(cache, str):\n            ds = dataset.cache(cache)\n        else:\n            ds = dataset.cache()\n\n    # Map each data point to an image-label pair and one-hot encode the label\n    ds = ds.map(lambda d: (d[\"image\"], tf.one_hot(d[\"label\"], num_classes)))\n\n    # Apply data augmentation if specified\n    if augment_data:\n        ds = ds.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n    # Shuffle the dataset and repeat indefinitely\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    \n    # Batch the dataset\n    ds = ds.batch(batch_size)\n    \n    # Prefetch the data for better performance\n    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    \n    return ds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the batch size for training and validation\nbatch_size = 64\n\n# Prepare the training dataset with data augmentation and specified batch size\ntrain_ds = prepare_for_training(train_ds, augment_data=True, batch_size=batch_size)\n\n# Prepare the validation dataset with the specified batch size (no augmentation)\nvalid_ds = prepare_for_training(valid_ds, batch_size=batch_size)\n\n# Loop over a small portion of the validation dataset to print the shape of an example\nfor example in valid_ds.take(1):\n    # Print the shape of the input image and its corresponding label\n    print(\"Validation Example - Image Shape:\", example[0].shape, \"Label Shape:\", example[1].shape)\n\n# Loop over a small portion of the training dataset to print the shape of an example\nfor example in train_ds.take(1):\n    # Print the shape of the input image and its corresponding label\n    print(\"Training Example - Image Shape:\", example[0].shape, \"Label Shape:\", example[1].shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(batch):\n    # Create a grid of subplots to display the batch of images and labels\n    plt.figure(figsize=(20, 20))\n    \n    # Loop through the batch and display each image and its corresponding label\n    for n in range(min(32, batch_size)):\n        ax = plt.subplot(batch_size//8, 8, n + 1)\n        \n        # Display the image\n        plt.imshow(batch[0][n])\n        \n        # Set the title of the subplot as the corresponding label (class name)\n        plt.title(class_names[tf.argmax(batch[1][n].numpy())])\n        \n        # Turn off axis labels\n        plt.axis('off')\n    \n    # Adjust the spacing between images\n    plt.subplots_adjust(wspace=0.15, hspace=0.10) \n    \n    # Save the plot as an image\n    plt.savefig(\"first_batch.png\")\n    \n    # Display the plot\n    plt.show()\n\n# Call the show_batch function to display a batch of images from the training dataset\nshow_batch(next(iter(train_ds)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the pre-trained model URL\nmodel_handle = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/2\"\n\n# Create a KerasLayer using the pre-trained model for feature extraction\nfeature_extractor = hub.KerasLayer(model_handle, output_shape=[1280], trainable=True)\n\n# Build the sequential model\nmodel = tf.keras.Sequential([\n    feature_extractor,\n    Dropout(0.5),  # Adding dropout with a rate of 0.5 (50% of units dropped out)\n    Dense(num_classes, activation=\"softmax\")\n])\n\n# Build the model with a specified input shape\nmodel.build([None, 64, 64, 3]) # input shape\n\n# Compile the model\nmodel.compile(\n    loss=\"categorical_crossentropy\", \n    #optimizer=\"Adam\", \n    optimizer=\"RMSprop\", \n    metrics=[\"accuracy\", tfa.metrics.F1Score(num_classes)])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the name and path for saving the trained model\nmodel_name = \"satellite_image_classifier\"\nmodel_path = os.path.join(\"output\", model_name + \".h5\")\n\n# Define callbacks for model training\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, verbose=1)\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n\n# Calculate the number of training and validation steps based on data size and batch size\nn_training_steps   = int(num_examples * 0.6) // batch_size\nn_validation_steps = int(num_examples * 0.2) // batch_size\n\n# Train the model using the training and validation datasets\nhistory = model.fit(\n    train_ds, \n    validation_data=valid_ds,\n    steps_per_epoch=n_training_steps,\n    validation_steps=n_validation_steps,\n    verbose=1, epochs=50, \ncallbacks=[model_checkpoint, early_stop]  # Adding early_stop callback here\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the trained model weights from the specified model path\nmodel.load_weights(model_path)\n\n# Calculate the number of testing steps based on a portion of the training dataset\nn_testing_steps = int(all_data[1].splits[\"train\"].num_examples * 0.2)\n\n# Get images and labels from the test dataset for evaluation\nimages = np.array([x[\"image\"] for x in test_ds.take(n_testing_steps)])\nprint(\"images shape:\", images.shape)\nlabels = np.array([x[\"label\"] for x in test_ds.take(n_testing_steps)])\nprint(\"labels shape:\", labels.shape)\n\n# Make predictions using the loaded model\npredictions = model.predict(images)\npredictions = np.argmax(predictions, axis=1)  # Convert probabilities to class indices\nprint(\"predictions.shape:\", predictions.shape)\n\n# Calculate accuracy and F1 score for model evaluation\nfrom sklearn.metrics import f1_score\n\naccuracy = tf.keras.metrics.Accuracy()\naccuracy.update_state(labels, predictions)\nprint(\"Accuracy:\", accuracy.result().numpy())\n\nf1_macro = f1_score(labels, predictions, average=\"macro\")\nprint(\"F1 Score (Macro):\", f1_macro)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the confusion matrix between the true labels and the predicted labels\ncm = tf.math.confusion_matrix(labels, predictions).numpy()\n\n# Normalize the confusion matrix to show percentages along each column\ncm = cm.astype('float') / cm.sum(axis=0)[:, np.newaxis]\n\n# Create a figure and axis for the heatmap visualization\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Create a heatmap of the normalized confusion matrix with annotations\nsns.heatmap(cm, annot=True, fmt='.2f', \n            xticklabels=[f\"{c}\" for c in class_names], \n            yticklabels=[f\"{c}\" for c in class_names],\n            cmap=\"rocket_r\"  # Choose the color map for better visibility\n            )\n\n# Set labels for the x-axis and y-axis\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\n# Save the heatmap visualization as an image\nplt.savefig(\"confusion_matrix.png\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to visualize a grid of predicted samples\ndef show_predicted_samples():\n    plt.figure(figsize=(14, 14))\n    \n    # Loop through a range of samples\n    for n in range(64):\n        ax = plt.subplot(8, 8, n + 1)\n        \n        # Display the image\n        plt.imshow(images[n])\n        \n        # If the prediction matches the true label, set title in green\n        if predictions[n] == labels[n]:\n            ax.set_title(class_names[predictions[n]], color=\"green\")\n        # If the prediction doesn't match the true label, set title in red\n        else:\n            ax.set_title(f\"{class_names[predictions[n]]}/T:{class_names[labels[n]]}\", color=\"red\")\n        \n        # Turn off axis labels\n        plt.axis('off')\n    \n    # Save the plot as an image\n    plt.savefig(\"predicted-sample-images.png\")\n\n# Call the show_predicted_samples function to display and save predicted sample images\nshow_predicted_samples()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define a function to plot training history metrics (accuracy and loss)\ndef plot_training_history(history):\n    fig, axs = plt.subplots(2, 1, figsize=(7, 7))\n    \n    # Plot training & validation accuracy values\n    axs[0].plot(history.history['accuracy'])\n    axs[0].plot(history.history['val_accuracy'])\n    axs[0].set_title('Model accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['Train', 'Validation'], loc='upper left')\n    \n    # Plot training & validation loss values\n    axs[1].plot(history.history['loss'])\n    axs[1].plot(history.history['val_loss'])\n    axs[1].set_title('Model loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['Train', 'Validation'], loc='upper left')\n    \n    # Adjust the layout and display the plot\n    plt.tight_layout()\n    plt.show()\n\n# Call the function to plot training history metrics\nplot_training_history(history)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}